---
title: "Recent streamMetabolizer improvements"
author: "Alison Appling"
date: "September 8, 2016"
output:
  rmdformats::readthedown:
    highlight: kate
---


```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             prompt=FALSE,
               tidy=TRUE)
opts_knit$set(width=75)
```

# Setup

Load streamMetabolizer. Note the new package startup messages.

```{r, messages=TRUE, warnings=TRUE, errors=TRUE}
library(streamMetabolizer)
```

More setup: load dplyr and get some data to work with.

```{r}
library(dplyr)
dat <- data_metab('3', '15')
```

# New results reporting

```{r}
# the Classic: linear GPP, constant ER (also the default)
mm_classic <- 
  mm_name('mle', GPP_fun='linlight', ER_fun='constant') %>% 
  specs() %>%
  metab(dat)
mm_classic
```

Note the fancy new print-out of the models. You can see up to the first 10 dates worth of fitted daily parameters and daily metabolism estimates. I've also made a distinction between daily parameters and daily metabolism which wasn't there before but now makes sense because the fitted parameters won't always directly represent the daily mean rates of metabolism. This will become even clearer with the next example.

# New GPP and ER functions

```{r}
# the Saturator: GPP saturating with light, constant ER
mm_saturator <- 
  mm_name('mle', GPP_fun='satlight', ER_fun='constant') %>% 
  specs() %>%
  metab(dat)
mm_saturator
```

The Saturator produces fitting warnings, which are condensed to 'w' and a summary in the above print-out. They can be inspected in detail by looking directly at the fitted daily parameters:

```{r}
get_params(mm_saturator) %>% select(date, warnings, errors)
```

Similary, you can inspect the warnings and errors that arise during prediction by pulling out the daily metabolism predictions (but there aren't any, so those columns are empty):

```{r}
predict_metab(mm_saturator)
```

It's still possible to predict instantaneous DO values, though these are omitted from the summary because there are too many data points.
```{r}
predict_DO(mm_saturator) %>% head
plot_DO_preds(mm_saturator)
```

Yep, that fitting warning on day 2 was meaningful! We can encourage the model toward a good fit by adjusting the initial values of Pmax and alpha from which the fitting function should explore likelihood space. There are two ways to do this - as date-specific values in data_daily, or as values that apply to every date in specs(). The two methods can even be combined.

```{r}
mm_saturator2 <- 
  mm_name('mle', GPP_fun='satlight', ER_fun='constant') %>% 
  specs() %>%
  metab(dat, data_daily=select(get_params(mm_saturator), date, init.Pmax=Pmax, init.alpha=alpha))
get_params(mm_saturator2)
mm_saturator3 <- 
  mm_name('mle', GPP_fun='satlight', ER_fun='constant') %>% 
  specs(init.Pmax=6.2, init.alpha=0.008) %>%
  metab(dat)
get_params(mm_saturator3)
mm_saturator4 <- 
  mm_name('mle', GPP_fun='satlight', ER_fun='constant') %>% 
  specs(init.Pmax=6.2, init.alpha=0.008) %>%
  metab(dat, transmute(get_params(mm_saturator), date, init.Pmax=Pmax[1], init.alpha=alpha[1])[2,])
get_params(mm_saturator4)
```

I've already put in code telling `nlm` about the expected ranges and good initial values for `Pmax` and `alpha` - this does help, and I think it's equivalent to scaling the parameters beforehand. So I'm not sure what else we can to do ensure that these models generate successful fits more often. Thoughts?

On the bright side, the fits on days 1 and 3 do look much nicer to me than they did for the classic model.

```{r}
plot_DO_preds(mm_classic)
```

See the lists of available functions for gross primary productivity (GPP), 
ecosystem respiration (ER), and reaeration (D). There's also a lot of
information in `?mm_name`.

```{r}
formals(mm_name)$GPP_fun
formals(mm_name)$ER_fun
# the reaeration parameter is named differently because it doesn't modify the 
# whole reaeration equation, just the deficit calculation
formals(mm_name)$deficit_src 
```

# Simulation

You can also simulate data using any of these fancy GPP and ER functions with models of type `'sim'`.

How do you know which daily parameters need to be included (besides looking at `?mm_name`?) Create the model and ask for the parameters and read the error message.

```{r}
mm_sim_q10 <- metab(specs(mm_name('sim', ER_fun='q10temp'), err.obs.sigma=0, err.proc.sigma=1), dat)
tryCatch( 
  get_params(mm_sim_q10) # you only need this line if you're running interactively
  , error=function(e) e$message)
```

Now we can pick parameters.

```{r}
params_sim_q10 <- data.frame(date=as.Date(paste0('2012-09-',18:20)), GPP.daily=2, ER20=-5:-3, K600.daily=16)
params_sim_q10
mm_sim_q10 <- metab(specs(mm_name('sim', ER_fun='q10temp'), err.obs.sigma=0, err.proc.sigma=1), dat, data_daily=params_sim_q10)
```

As before, simulations can generate new noise each time.

```{r, fig.height=2}
plot_DO_preds(mm_sim_q10, y_var='conc')
plot_DO_preds(mm_sim_q10, y_var='conc')
```

You can also re-use parameters from another model as your input for data_daily if you ask for them in the right format (useful for starting with realistic parameters and/or exploring why a model didn't work so well)

```{r}
params_sim_sat <- get_params(mm_saturator, uncertainty='none', messages=FALSE)
mm_sim_sat <- metab(specs(mm_name('sim', GPP_fun='satlight'), err.obs.sigma=0, err.proc.sigma=1), dat, data_daily=params_sim_sat)
```
```{r, fig.height=2}
plot_DO_preds(mm_sim_sat, y_var='conc')
plot_DO_preds(mm_sim_sat, y_var='conc')
```

Also notice that sim models print out their parameters with asterisks to denote that the values are fixed rather than fitted, and they produce daily estimates of GPP and ER which should help in choosing simulation parameters. (Behind the scenes, this also means we now have the capacity to predict instantaneous GPP and ER and reaeration...should we expose that?)

```{r}
mm_sim_sat
```

I've been playing around with the units of `err.proc.sigma` and have recently been thinking that I prefer for the units to be ecologically meaningful and comparable to GPP and ER; they are thus scaled by depth and timestep length. See the `err.proc` argument in `?create_calc_dDOdt`, which says 

> optional numerical vector of length nrow(data). Process error in units of gO2 m^-2 d^-1 (THIS MAY DIFFER FROM WHAT YOU'RE USED TO!). Appropriate for simulation, when this vector of process errors will be added to the calculated values of GPP and ER (then divided by depth and multiplied by timestep duration) to simulate process error. But usually (for MLE or prediction from a fitted MLE/Bayesian/nighttime regression model) err.proc should be missing or 0.

Probably some room for discussion here. The idea would be to make process error mean the same thing across temporal resolutions - I think but am not totally sure I've achieved this.

```{r}
params_sim_q10_ab <- data.frame(date=as.Date(paste0('2012-09-',18:20)), GPP.daily=2, ER20=-2, K600.daily=6)
dat_a <- data_metab('3', res='5')
mm_sim_q10_a <- metab(specs(mm_name('sim', ER_fun='q10temp'), err.obs.sigma=0, err.proc.sigma=2), dat_a, data_daily=params_sim_q10)
plot_DO_preds(mm_sim_q10_a, y_var='conc')
dat_b <- data_metab('3', res='30')
mm_sim_q10_b <- metab(specs(mm_name('sim', ER_fun='q10temp'), err.obs.sigma=0, err.proc.sigma=2), dat_b, data_daily=params_sim_q10)
plot_DO_preds(mm_sim_q10_b, y_var='conc')
```

# Numerical integration

Inspired by Song et al. 2016, we can now do several types of numerical integration and compare them. `lsoda` fails to converge more often, but `rk4` and `trapezoid` perform well and very similarly to one another (and `trapezoid` is faster).

```{r}
dat <- data_metab('3','30')
mm_euler <- metab(specs(mm_name('mle', ode_method='euler')), dat)
mm_trapezoid <- metab(specs(mm_name('mle', ode_method='trapezoid')), dat)
mm_rk4 <- metab(specs(mm_name('mle', ode_method='rk4')), dat) 
mm_lsoda <- metab(specs(mm_name('mle', ode_method='lsoda')), dat) 
DO.standard <- rep(predict_DO(mm_rk4)$'DO.mod', times=4)
ode_preds <- bind_rows(
  mutate(predict_DO(mm_euler), method='euler'),
  mutate(predict_DO(mm_trapezoid), method='trapezoid'),
  mutate(predict_DO(mm_rk4), method='rk4'),
  mutate(predict_DO(mm_lsoda), method='lsoda')) %>%
  mutate(DO.mod.diffeuler = DO.mod - DO.standard)
library(ggplot2)
ggplot(ode_preds, aes(x=solar.time)) + geom_point(aes(y=DO.obs), color='grey', alpha=0.3) + geom_line(aes(y=DO.mod, color=method), size=1) + theme_bw()
ggplot(ode_preds, aes(x=solar.time)) + geom_point(aes(y=pmax(-0.2, pmin(0.2, DO.mod.diffeuler)), color=method), size=1, alpha=0.8) + scale_y_continuous(limits=c(-0.2,0.2)) + theme_bw()
```

# Code considerations

Importantly for code robustness's sake, the MLE and simulator and DO prediction models all use the exact same code behind the scenes. So from here on out it should be possible to add/modify equations for GPP or ER and have them immediately available and consistent across all models. (Except the Bayesian ones, for which the prediction will be consistent but I need to add in the model fitting flexibility.)
And this is also true (again except the Bayesian models) for the numerical integration methods.
